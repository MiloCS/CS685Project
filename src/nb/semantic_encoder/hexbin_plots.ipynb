{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DATA_DIR = \"data\" # This may need to be changed on different machines\n",
    "# Make sure we're in the correct directory and make sure the data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.chdir(\"../../..\") # Move up two directories because we're in src/nb and the data directory/path should be in/start at the root directory \n",
    "    assert os.path.exists(DATA_DIR), f\"ERROR: DATA_DIR={DATA_DIR} not found\"  # If we still can't see the data directory something is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "small_model = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = small_model # Some huggingface model\n",
    "dataset_prefix = \"train\" # dev train test\n",
    "dataset_balanced = True # True or False\n",
    "text_type = \"paraphrase\" # \"paraphrase\" or \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b043f26e1a2a855c\n",
      "Reusing dataset csv (/home/bill/.cache/huggingface/datasets/csv/default-b043f26e1a2a855c/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3219f772cce45588c051fb7e0625f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'text', 'paraphrase', '__index_level_0__'],\n",
      "    num_rows: 273373\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"decoded_cds\",\n",
    "    \"balanced\" if dataset_balanced else \"unbalanced\",\n",
    "    f\"{dataset_prefix}.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# get dataset as PyTorch Dataset\n",
    "dataset = load_dataset(\"csv\", data_files=dataset_path, names=[\"label\", \"text\", \"paraphrase\"])[\"train\"] # Not sure if \"train\" is always what we want... it seems to be the default name\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7482d42d8a34951af62f2f5627eb0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f718ae52c0d49cfb0d9cfd4db04e2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0532d69b58864b628798fb9c6be9f75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c448648a58f439b958270c1ce1e2233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4698a5d25aee4162a444d54897e91046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54401492fed49beb47e462b4cb753cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/86.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 11498,  8458,  ...,     0,     0,     0],\n",
       "        [  101,  2002,  2987,  ...,     0,     0,     0],\n",
       "        [  101,  2002,  1005,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1996,  2214,  ...,     0,     0,     0],\n",
       "        [  101,  2002,  8451,  ...,     0,     0,     0],\n",
       "        [  101,  2296,  2305,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "encoded_paraphrase = tokenize(dataset[text_type])\n",
    "encoded_paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Compute token embeddings\n",
    "inputs = {\n",
    "    \"input_ids\": encoded_paraphrase[\"input_ids\"],\n",
    "    \"attention_mask\": encoded_paraphrase[\"attention_mask\"]\n",
    "}\n",
    "all_sentence_embeddings = []\n",
    "batch_size = 512\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(encoded_paraphrase[\"input_ids\"]), batch_size)):\n",
    "        input_ids = encoded_paraphrase[\"input_ids\"][i:i+batch_size].to(device)\n",
    "        attention_mask = encoded_paraphrase[\"attention_mask\"][i:i+batch_size].to(device)\n",
    "\n",
    "        batch_output = model(input_ids, attention_mask)\n",
    "\n",
    "        # Perform pooling\n",
    "        sentence_embeddings = mean_pooling(batch_output, attention_mask)\n",
    "\n",
    "        # Normalize embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "        # take the sentence embeddings off the GPU\n",
    "        sentence_embeddings = sentence_embeddings.cpu()\n",
    "\n",
    "        # Append to list\n",
    "        all_sentence_embeddings.append(sentence_embeddings)\n",
    "\n",
    "# Concatenate all embeddings\n",
    "sentence_embeddings = torch.cat(all_sentence_embeddings, dim=0)\n",
    "\n",
    "# Embedding Shape\n",
    "print(f\"Sentence Embeddings Shape: {sentence_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings as npy DATA_DIR/embedded_cds/is_balanced/prefix_dim.npy\n",
    "embedding_save_file = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"embedded_cds\",\n",
    "    \"balanced\" if dataset_balanced else \"unbalanced\",\n",
    "    f\"{dataset_prefix}_{model_name.split('/')[-1]}.npy\"\n",
    ")\n",
    "\n",
    "np.save(embedding_save_file, sentence_embeddings.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embeddings\n",
    "sentence_embeddings = np.load(\"data/paraphrase_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project the sentence emebeddings to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_embeddings = tsne.fit_transform(sentence_embeddings.numpy())\n",
    "\n",
    "# visualize the embeddings\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1])\n",
    "\n",
    "# save the plot\n",
    "plt.savefig(\"data/sentence_embeddings.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pca to reduce the dimensionality of the embeddings to 2D\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_embeddings = pca.fit_transform(sentence_embeddings)\n",
    "\n",
    "# save pca embeddings\n",
    "np.save(\"data/pca_embeddings.npy\", pca_embeddings)\n",
    "\n",
    "hexbin_plot(pca_embeddings[:, 0], pca_embeddings[:, 1], np.array(cds[\"validation\"][\"label\"]))\n",
    "plt.savefig(\"data/pca_hexbin.png\", facecolor=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tsne_embeddings as npy\n",
    "np.save(\"data/tsne_embeddings.npy\", tsne_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "# plot the tsne embeddings and color them by the labels\n",
    "# random color\n",
    "\n",
    "labels_to_color = {k:np.random.random(size=3) for k in set(cds[\"validation\"][\"label\"])}\n",
    "\n",
    "\n",
    "\n",
    "random_inds = np.random.choice(len(pca_embeddings), size=100000, replace=False).astype(int)\n",
    "random_embeddings = pca_embeddings[random_inds]\n",
    "random_labels = np.array(cds[\"validation\"][\"label\"])[random_inds]\n",
    "\n",
    "colors = list(map(lambda x: labels_to_color[x], random_labels))\n",
    "\n",
    "for label in set(cds[\"validation\"][\"label\"]):\n",
    "    inds = np.where(random_labels == label)[0]\n",
    "    plt.scatter(random_embeddings[inds, 0], random_embeddings[inds, 1], label=label)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# save the plot\n",
    "plt.savefig(\"data/sentence_embeddings.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scaled_embeddings = MinMaxScaler().fit_transform(sentence_embeddings)\n",
    "mapper = UMAP(n_components=2, metric=\"cosine\").fit(scaled_embeddings)\n",
    "\n",
    "df_emb = pd.DataFrame(mapper.embedding_, columns=[\"x\", \"y\"])\n",
    "df_emb[\"label\"] = cds[\"validation\"][\"label\"]\n",
    "df_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexbin_plot(df_emb[\"x\"], df_emb[\"y\"], df_emb[\"label\"])\n",
    "plt.savefig(\"data/umap_hexbin.png\", facecolor=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear classifier on the embeddings\n",
    "embedding_dim = sentence_embeddings.shape[1]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "linear_layer = nn.Linear(embedding_dim, 11).to(device)\n",
    "\n",
    "string_labels = np.array(cds[\"validation\"][\"label\"])\n",
    "label_to_int = {k:i for i, k in enumerate(set(string_labels))}\n",
    "# integer labels\n",
    "int_labels = np.array(list(map(lambda x: label_to_int[x], string_labels)))\n",
    "\n",
    "shuffled_inds = np.random.choice(len(int_labels), size=len(int_labels), replace=False).astype(int)\n",
    "\n",
    "train_inds = shuffled_inds[:int(len(int_labels) * 0.8)]\n",
    "val_inds = shuffled_inds[int(len(int_labels) * 0.8):]\n",
    "\n",
    "optimizer = torch.optim.Adam(linear_layer.parameters(), lr=0.001)\n",
    "\n",
    "batch_size = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(25):\n",
    "    loss_ewma = 0\n",
    "    loss_count = 0\n",
    "    pbar = tqdm(range(0, len(train_inds), batch_size))\n",
    "    for batch in pbar:\n",
    "        inds = train_inds[batch:batch+batch_size]\n",
    "\n",
    "        batch_embeddings = sentence_embeddings[inds]\n",
    "        batch_labels = int_labels[inds]\n",
    "\n",
    "        batch_embeddings = torch.from_numpy(batch_embeddings).to(device)\n",
    "        batch_labels = torch.from_numpy(batch_labels).to(device)\n",
    "\n",
    "        batch_output = linear_layer(batch_embeddings)\n",
    "\n",
    "        loss = F.cross_entropy(batch_output, batch_labels)\n",
    "        loss_count += 1\n",
    "\n",
    "        loss_ewma = loss_ewma * 0.9 + loss * 0.1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update pbar\n",
    "        pbar.set_description(f\"Epoch {epoch} Loss: {loss_ewma.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "val_embeddings = torch.from_numpy(sentence_embeddings[val_inds]).to(device)\n",
    "preds = linear_layer(val_embeddings).argmax(dim=1)\n",
    "val_labels = torch.from_numpy(int_labels[val_inds]).to(device)\n",
    "acc = (preds == val_labels).float().mean()\n",
    "print(f\"Validation accuracy: {acc.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of a confusion matrix\n",
    "\n",
    "y_true = val_labels.cpu().numpy()\n",
    "y_pred = preds.cpu().numpy()\n",
    "\n",
    "classes = list(set(y_true))\n",
    "\n",
    "conf_mat = np.zeros((len(classes), len(classes)))\n",
    "for r in range(len(classes)):\n",
    "    for c in range(len(classes)):\n",
    "        conf_mat[r, c] = ((y_true == classes[r]) & (y_pred == classes[c])).sum()\n",
    "\n",
    "conf_mat /= conf_mat.sum(axis=1, keepdims=True)\n",
    "# conf_mat /= conf_mat.sum() * 0.01\n",
    "\n",
    "# plot the matrix\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(conf_mat)\n",
    "\n",
    "# Draw the values inside the matrix\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, f\"{conf_mat[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"red\")\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(len(classes)), set(string_labels), rotation=45)\n",
    "plt.yticks(np.arange(len(classes)), set(string_labels))\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.title(f\"Confusion matrix for validation set\")\n",
    "plt.savefig(\"data/confusion_matrix.png\", facecolor=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the total label counts for each class\n",
    "for label in set(string_labels):\n",
    "    print(f\"{label}: {(string_labels == label).sum()}\")\n",
    "\n",
    "# Make a bar graph of the label counts\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.bar(np.arange(len(classes)), [(string_labels == label).sum()/len(string_labels) for label in set(string_labels)])\n",
    "plt.xticks(np.arange(len(classes)), set(string_labels), rotation=45)\n",
    "plt.ylabel(\"Fraction of samples\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.title(f\"Fraction of samples for each label\")\n",
    "plt.savefig(\"data/label_counts.png\", facecolor=\"white\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5854a06c42c722c9b376878a2b0ccc4f0377baad6105251f5d0bcbe5a7e06c30"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
