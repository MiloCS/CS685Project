{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "DATA_DIR = \"data\" # This may need to be changed on different machines\n",
    "\n",
    "# Make sure we're in the correct directory and make sure the data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.chdir(\"../..\") # Move up two directories because we're in src/nb and the data directory/path should be in/start at the root directory \n",
    "    assert os.path.exists(DATA_DIR), f\"ERROR: DATA_DIR={DATA_DIR} not found\"  # If we still can't see the data directory something is wrong\n",
    "\n",
    "# Import library things after changing directories\n",
    "from src.lib.bpe_parser import read_bpe_data, read_int_to_token, decode_bpe_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_data_path = os.path.join(DATA_DIR, \"datasets\", \"cds\", \"tweets\", \"dev.input0.bpe\")\n",
    "vocab_path = os.path.join(DATA_DIR, \"vocabs\", \"tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_data = read_bpe_data(bpe_data_path)\n",
    "vocab_dict = read_int_to_token(vocab_path)\n",
    "decoded_data = decode_bpe_to_text(bpe_data, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Star Classic Game 1 Orlando 09 Game 1 - West Coast vs East\n",
      "The official morning baddie is Oleana from Pokemon Sword and Shield\n",
      "Very cute and also very, very sexy. Love your Heels too.\n",
      "I drive all night to keep her warm\n",
      "pastorobeds jesusdaily love.quotes ibphialeah #pray #prayer #f #hope #biblia #life\n",
      "To all the girls out there who are genuinely nice & not bitches, ily\n",
      "the only Disney princess\n",
      "What do you mean our faves child rapists, Kemosabe?\n",
      "Ffs Tommy, stop tryna make man cry\n",
      "Sunny Side Up please... with extra Irene.\n"
     ]
    }
   ],
   "source": [
    "# print first 10 decoded sentences\n",
    "for i in range(10):\n",
    "    print(decoded_data[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbb993f87c2f34e1a4bfcb428fa22ffc0771c3a7511e6f0a0e3d039efe614c2a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
