{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "DATA_DIR = \"data\" # This may need to be changed on different machines\n",
    "\n",
    "# Make sure we're in the correct directory and make sure the data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.chdir(\"../..\") # Move up two directories because we're in src/nb and the data directory/path should be in/start at the root directory \n",
    "    assert os.path.exists(DATA_DIR), f\"ERROR: DATA_DIR={DATA_DIR} not found\"  # If we still can't see the data directory something is wrong\n",
    "\n",
    "# Import library things after changing directories\n",
    "from src.lib.bpe_parser import read_bpe_data, read_int_to_token, decode_bpe_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_data_path = os.path.join(DATA_DIR, \"datasets\", \"cds\", \"tweets\", \"dev.input0.bpe\")\n",
    "vocab_path = os.path.join(DATA_DIR, \"vocabs\", \"tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_data = read_bpe_data(bpe_data_path)\n",
    "vocab_dict = read_int_to_token(vocab_path)\n",
    "decoded_data = decode_bpe_to_text(bpe_data, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Star Classic Game 1 Orlando 09 Game 1 - West Coast vs East\n",
      "The official morning baddie is Oleana from Pokemon Sword and Shield\n",
      "Very cute and also very, very sexy. Love your Heels too.\n",
      "I drive all night to keep her warm\n",
      "pastorobeds jesusdaily love.quotes ibphialeah #pray #prayer #f #hope #biblia #life\n",
      "To all the girls out there who are genuinely nice & not bitches, ily\n",
      "the only Disney princess\n",
      "What do you mean our faves child rapists, Kemosabe?\n",
      "Ffs Tommy, stop tryna make man cry\n",
      "Sunny Side Up please... with extra Irene.\n"
     ]
    }
   ],
   "source": [
    "# print first 10 decoded sentences\n",
    "for i in range(10):\n",
    "    print(decoded_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joyce',\n",
       " 'poetry',\n",
       " 'coha_1810',\n",
       " 'tweets',\n",
       " 'coha_1890',\n",
       " 'coha_1990',\n",
       " 'switchboard',\n",
       " 'lyrics',\n",
       " 'bible',\n",
       " 'shakespeare',\n",
       " 'aae']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds_dir = os.path.join(DATA_DIR, \"datasets\", \"cds\")\n",
    "cds_types = os.listdir(cds_dir)\n",
    "cds_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01b1ea01f684dad8cde33ad8bbbead0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use this to specify which files we want to decode\n",
    "filter_files = lambda file_name: file_name.endswith(\".bpe\") and file_name.startswith(\"dev\")\n",
    "\n",
    "for cds_type in tqdm(cds_types):\n",
    "    cds_path = os.path.join(cds_dir, cds_type)\n",
    "    cds_files = [file for file in os.listdir(cds_path) if filter_files(file)]\n",
    "    for cds_file in cds_files:\n",
    "        cds_file_path = os.path.join(cds_path, cds_file)\n",
    "        cds_data = read_bpe_data(cds_file_path)\n",
    "        cds_data_decoded = decode_bpe_to_text(cds_data, vocab_dict)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            \"text\": cds_data_decoded,\n",
    "            \"label\": [cds_type] * len(cds_data_decoded)\n",
    "        })\n",
    "        # save to csv cds_path/cds_file.csv\n",
    "        base_name = os.path.splitext(cds_file)[0]\n",
    "        df.to_csv(os.path.join(cds_path, base_name + \".csv\"), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31a16f746a04796a68067b929db0edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I had something for you</td>\n",
       "      <td>lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There were times we had it all</td>\n",
       "      <td>lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chiefly important, however, is the fact that t...</td>\n",
       "      <td>coha_1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You stay 5 minutes away though lol</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was on the look out for the wolf</td>\n",
       "      <td>lyrics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      label\n",
       "0                            I had something for you     lyrics\n",
       "1                     There were times we had it all     lyrics\n",
       "2  Chiefly important, however, is the fact that t...  coha_1890\n",
       "3                 You stay 5 minutes away though lol     tweets\n",
       "4                 I was on the look out for the wolf     lyrics"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_files = lambda file_name: file_name.startswith(\"dev.input0\") and file_name.endswith(\".csv\")\n",
    "\n",
    "df = None\n",
    "\n",
    "for cds_type in tqdm(cds_types):\n",
    "    cds_path = os.path.join(cds_dir, cds_type)\n",
    "    csv_files = [file for file in os.listdir(cds_path) if filter_files(file)]\n",
    "    for csv_file in csv_files:\n",
    "        sub_df = pd.read_csv(os.path.join(cds_path, csv_file))\n",
    "        if df is None:\n",
    "            df = sub_df\n",
    "        else:\n",
    "            df = pd.concat([df, sub_df])\n",
    "\n",
    "# save df in cds_path/all_data.csv\n",
    "df.to_csv(os.path.join(cds_dir, \"dev.cds.csv\"), index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbb993f87c2f34e1a4bfcb428fa22ffc0771c3a7511e6f0a0e3d039efe614c2a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
