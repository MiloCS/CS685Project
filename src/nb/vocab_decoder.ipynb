{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "DATA_DIR = \"data\" # This may need to be changed on different machines\n",
    "\n",
    "# Make sure we're in the correct directory and make sure the data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.chdir(\"../..\") # Move up two directories because we're in src/nb and the data directory/path should be in/start at the root directory \n",
    "    assert os.path.exists(DATA_DIR), f\"ERROR: DATA_DIR={DATA_DIR} not found\"  # If we still can't see the data directory something is wrong\n",
    "\n",
    "# Import library things after changing directories\n",
    "from src.lib.bpe_parser import read_bpe_data, read_int_to_token, decode_bpe_to_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the functions to manipulate BPE data seem to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_data_path = os.path.join(DATA_DIR, \"datasets\", \"cds\", \"tweets\", \"dev.input0.bpe\")\n",
    "vocab_path = os.path.join(DATA_DIR, \"vocabs\", \"tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_data = read_bpe_data(bpe_data_path)\n",
    "vocab_dict = read_int_to_token(vocab_path)\n",
    "decoded_data = decode_bpe_to_text(bpe_data, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "All Star Classic Game 1 Orlando 09 Game 1 - West Coast vs East\n"
     ]
    }
   ],
   "source": [
    "print(type(decoded_data))\n",
    "print(decoded_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Star Classic Game 1 Orlando 09 Game 1 - West Coast vs East\n",
      "The official morning baddie is Oleana from Pokemon Sword and Shield\n",
      "Very cute and also very, very sexy. Love your Heels too.\n",
      "I drive all night to keep her warm\n",
      "pastorobeds jesusdaily love.quotes ibphialeah #pray #prayer #f #hope #biblia #life\n",
      "To all the girls out there who are genuinely nice & not bitches, ily\n",
      "the only Disney princess\n",
      "What do you mean our faves child rapists, Kemosabe?\n",
      "Ffs Tommy, stop tryna make man cry\n",
      "Sunny Side Up please... with extra Irene.\n"
     ]
    }
   ],
   "source": [
    "# print first 10 decoded sentences\n",
    "for i in range(10):\n",
    "    print(decoded_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate csv files for each category in the cds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joyce',\n",
       " 'poetry',\n",
       " 'coha_1810',\n",
       " 'tweets',\n",
       " 'coha_1890',\n",
       " 'coha_1990',\n",
       " 'switchboard',\n",
       " 'lyrics',\n",
       " 'bible',\n",
       " 'shakespeare',\n",
       " 'aae']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds_dir = os.path.join(DATA_DIR, \"datasets\", \"cds\")\n",
    "cds_types = [dir_name for dir_name in os.listdir(cds_dir) if os.path.isdir(os.path.join(cds_dir, dir_name))]\n",
    "cds_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71aa6a4f07345e39b37c6563e6b3e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use this to specify which files we want to decode\n",
    "filter_files = lambda file_name: file_name.endswith(\".bpe\") and file_name.startswith(\"train\")\n",
    "\n",
    "for cds_type in tqdm(cds_types):\n",
    "    cds_path = os.path.join(cds_dir, cds_type)\n",
    "    cds_files = [file for file in os.listdir(cds_path) if filter_files(file)]\n",
    "    for cds_file in cds_files:\n",
    "        cds_file_path = os.path.join(cds_path, cds_file)\n",
    "        cds_data = read_bpe_data(cds_file_path)\n",
    "\n",
    "        vocab_path = os.path.join(DATA_DIR, \"vocabs\", f\"{cds_type}.json\")\n",
    "        vocab_dict = read_int_to_token(vocab_path)\n",
    "\n",
    "        cds_data_decoded = decode_bpe_to_text(cds_data, vocab_dict)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            \"text\": cds_data_decoded,\n",
    "            \"label\": [cds_type] * len(cds_data_decoded)\n",
    "        })\n",
    "        # save to csv cds_path/cds_file.csv\n",
    "        base_name = os.path.splitext(cds_file)[0]\n",
    "        df.to_csv(os.path.join(cds_path, base_name + \".csv\"), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all the csv files into one big csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b827d8059e784654978e161836afc9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393727\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>paraphrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joyce</td>\n",
       "      <td>in short circuit.</td>\n",
       "      <td>in short, the circuit was broken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joyce</td>\n",
       "      <td>Botlettle I thought sheâĢĻd act that loa.</td>\n",
       "      <td>I thought she would have done it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joyce</td>\n",
       "      <td>Round him peered Lenehan.</td>\n",
       "      <td>he looked at Lenehan round.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joyce</td>\n",
       "      <td>Do you pay rent for this tower?</td>\n",
       "      <td>you're paying rent for the tower?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joyce</td>\n",
       "      <td>HeâĢĻs from beyant Boyne water.</td>\n",
       "      <td>he's from the water in the Boyne.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                       text  \\\n",
       "0  joyce                          in short circuit.   \n",
       "1  joyce  Botlettle I thought sheâĢĻd act that loa.   \n",
       "2  joyce                  Round him peered Lenehan.   \n",
       "3  joyce            Do you pay rent for this tower?   \n",
       "4  joyce            HeâĢĻs from beyant Boyne water.   \n",
       "\n",
       "                          paraphrase  \n",
       "0  in short, the circuit was broken.  \n",
       "1  I thought she would have done it.  \n",
       "2        he looked at Lenehan round.  \n",
       "3  you're paying rent for the tower?  \n",
       "4  he's from the water in the Boyne.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = \"dev\" # Valid values: dev, train, test\n",
    "filter_files = lambda file_name: file_name.startswith(prefix) and file_name.endswith(\".csv\")\n",
    "\n",
    "df = None\n",
    "\n",
    "for cds_type in tqdm(cds_types):\n",
    "    cds_path = os.path.join(cds_dir, cds_type)\n",
    "    csv_files = [file for file in os.listdir(cds_path) if filter_files(file)]\n",
    "    assert len(csv_files) == 2, f\"ERROR: Expected 2 csv files for {cds_type}, found {len(csv_files)}\"\n",
    "\n",
    "    input_file_name = [file for file in csv_files if \".input\" in file][0]\n",
    "    paraphrase_file_name = [file for file in csv_files if \"paraphrase\" in file][0]\n",
    "\n",
    "    input_df = pd.read_csv(os.path.join(cds_path, input_file_name))\n",
    "\n",
    "    paraphrase_df = pd.read_csv(os.path.join(cds_path, paraphrase_file_name))\n",
    "\n",
    "    input_df[\"paraphrase\"] = paraphrase_df[\"text\"]\n",
    "\n",
    "    # oder columns label, text, paraphrase\n",
    "    input_df = input_df[[\"label\", \"text\", \"paraphrase\"]]\n",
    "\n",
    "    if df is None:\n",
    "        df = input_df\n",
    "    else:\n",
    "        df = pd.concat([df, input_df])\n",
    "\n",
    "# save df in cds_path/all_data.csv\n",
    "df.to_csv(os.path.join(cds_dir, f\"{prefix}.cds.csv\"), index=False)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbb993f87c2f34e1a4bfcb428fa22ffc0771c3a7511e6f0a0e3d039efe614c2a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
