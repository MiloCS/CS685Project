{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"data\" # This may need to be changed on different machines\n",
    "\n",
    "# Make sure we're in the correct directory and make sure the data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.chdir(\"../..\") # Move up two directories because we're in src/nb and the data directory/path should be in/start at the root directory \n",
    "    assert os.path.exists(DATA_DIR), f\"ERROR: DATA_DIR={DATA_DIR} not found\"  # If we still can't see the data directory something is wrong\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "# from torch import nn\n",
    "# get Dataset class\n",
    "from src.lib.decoder import Decoder\n",
    "from src.lib.paraphrase_model import Paraphraser\n",
    "from src.lib.style_classifier import StyleEncoder\n",
    "from src.lib.style_transfer import StyleTransferer\n",
    "# from src.lib.util import to_device\n",
    "# from transformers import GPT2LMHeadModel, AdamW, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_decoder(state_dict_path):\n",
    "    state_dict = torch.load(state_dict_path)\n",
    "    for key in state_dict:\n",
    "        state_dict[key] = state_dict[key].cpu()\n",
    "    decoder = Decoder()\n",
    "    decoder.load_state_dict(state_dict)\n",
    "    return decoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at models/gpt2_large were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.weight', 'transformer.extra_embedding_project.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at models/gpt2_large were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.weight', 'transformer.extra_embedding_project.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path = \"training_results/decoder_0_0.0979/model.pth\"\n",
    "decoder = load_decoder(path)\n",
    "paraphraser = Paraphraser()\n",
    "style_encoder = StyleEncoder()\n",
    "style_transferer = StyleTransferer(style_encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>paraphrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coha_1890</td>\n",
       "      <td>The imprisonment of Grotius was not the worst ...</td>\n",
       "      <td>Grotius was not the worst of all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poetry</td>\n",
       "      <td>The unfettered sun takes his unbounded reign</td>\n",
       "      <td>the unfettered sun is free to reign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aae</td>\n",
       "      <td>lol srry fun question but keep your head up do...</td>\n",
       "      <td>excuse me, but I'm sorry, but I'm sorry, but I'm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coha_1890</td>\n",
       "      <td>I tried to speak, but could not . \"</td>\n",
       "      <td>I'm trying to talk, but I can't.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poetry</td>\n",
       "      <td>Dancing upon the waves, as if to please</td>\n",
       "      <td>dancing on the waves, as if they were happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14218</th>\n",
       "      <td>coha_1810</td>\n",
       "      <td>A high railing ran, rough and irregular, along...</td>\n",
       "      <td>just as we were, the high railing was rough an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14219</th>\n",
       "      <td>shakespeare</td>\n",
       "      <td>Mercy but murders, pardoning those that kill.</td>\n",
       "      <td>mercy, mercy, mercy, mercy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14220</th>\n",
       "      <td>coha_1810</td>\n",
       "      <td>The house at which I proposed to stop was upwa...</td>\n",
       "      <td>the house I'd like to stop is a mile away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14221</th>\n",
       "      <td>coha_1990</td>\n",
       "      <td>The only thing is, Grandma's going a bit batty.</td>\n",
       "      <td>the only thing is, Grandma's a little crazy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14222</th>\n",
       "      <td>lyrics</td>\n",
       "      <td>The closer you get, oh baby the further I fall</td>\n",
       "      <td>the closer I'm going, the worse.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14223 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                               text  \\\n",
       "0        coha_1890  The imprisonment of Grotius was not the worst ...   \n",
       "1           poetry       The unfettered sun takes his unbounded reign   \n",
       "2              aae  lol srry fun question but keep your head up do...   \n",
       "3        coha_1890                I tried to speak, but could not . \"   \n",
       "4           poetry            Dancing upon the waves, as if to please   \n",
       "...            ...                                                ...   \n",
       "14218    coha_1810  A high railing ran, rough and irregular, along...   \n",
       "14219  shakespeare     Mercy but murders, pardoning those that kill.    \n",
       "14220    coha_1810  The house at which I proposed to stop was upwa...   \n",
       "14221    coha_1990    The only thing is, Grandma's going a bit batty.   \n",
       "14222       lyrics     The closer you get, oh baby the further I fall   \n",
       "\n",
       "                                              paraphrase  \n",
       "0                      Grotius was not the worst of all.  \n",
       "1                    the unfettered sun is free to reign  \n",
       "2       excuse me, but I'm sorry, but I'm sorry, but I'm  \n",
       "3                       I'm trying to talk, but I can't.  \n",
       "4            dancing on the waves, as if they were happy  \n",
       "...                                                  ...  \n",
       "14218  just as we were, the high railing was rough an...  \n",
       "14219                        mercy, mercy, mercy, mercy.  \n",
       "14220         the house I'd like to stop is a mile away.  \n",
       "14221       the only thing is, Grandma's a little crazy.  \n",
       "14222                   the closer I'm going, the worse.  \n",
       "\n",
       "[14223 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/decoded_cds/balanced/test.csv\", index_col=0)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b4d4ae60d8494e9e5ed1f90f6c700f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=11'>12</a>\u001b[0m random_text \u001b[39m=\u001b[39m label_groups\u001b[39m.\u001b[39mget_group(label)\u001b[39m.\u001b[39msample(\u001b[39m1\u001b[39m)[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=13'>14</a>\u001b[0m sample \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=14'>15</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msemantic_sentence\u001b[39m\u001b[39m\"\u001b[39m: text,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=15'>16</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mparaphrase\u001b[39m\u001b[39m\"\u001b[39m: paraphrase,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=16'>17</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstyle_sentence\u001b[39m\u001b[39m\"\u001b[39m: random_text,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=17'>18</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: label,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=18'>19</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=20'>21</a>\u001b[0m transferred_sentence \u001b[39m=\u001b[39m style_transferer\u001b[39m.\u001b[39;49mtransfer_style(text, random_text, truncate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, max_length\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=21'>22</a>\u001b[0m sample[\u001b[39m\"\u001b[39m\u001b[39mtransferred_sentence\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m transferred_sentence\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/get_data_for_eval.ipynb#ch0000004vscode-remote?line=23'>24</a>\u001b[0m output_df\u001b[39m.\u001b[39mloc[i] \u001b[39m=\u001b[39m sample\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/src/lib/style_transfer.py:132\u001b[0m, in \u001b[0;36mStyleTransferer.transfer_style\u001b[0;34m(self, semantic_sentence, style_sentence, truncate, max_length)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=129'>130</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransfer_style\u001b[39m(\u001b[39mself\u001b[39m, semantic_sentence, style_sentence, truncate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_length\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=130'>131</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_input(semantic_sentence, style_sentence)\n\u001b[0;32m--> <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=131'>132</a>\u001b[0m     generated_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(x, truncate\u001b[39m=\u001b[39;49mtruncate, max_length\u001b[39m=\u001b[39;49mmax_length)\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=132'>133</a>\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mdecode(generated_ids)\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=133'>134</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/src/lib/style_transfer.py:104\u001b[0m, in \u001b[0;36mStyleTransferer.generate\u001b[0;34m(self, x, truncate, max_length)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=99'>100</a>\u001b[0m generated_logits\u001b[39m.\u001b[39mappend(logits)\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=102'>103</a>\u001b[0m \u001b[39m# check if token_id is eos\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=103'>104</a>\u001b[0m \u001b[39mif\u001b[39;00m token_id \u001b[39m==\u001b[39m decoder\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39meos_token_id:\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=104'>105</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_transfer.py?line=106'>107</a>\u001b[0m \u001b[39m# add generated id \u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame(columns=[\"semantic_sentence\", \"paraphrase\", \"style_sentence\", \"label\", \"transferred_sentence\"])\n",
    "\n",
    "label_groups = test_df.groupby(\"label\")\n",
    "\n",
    "# use tqdm and iterrows over dataframe\n",
    "for i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    label, text = row[\"label\"], row[\"text\"]\n",
    "    paraphrase = row[\"paraphrase\"]\n",
    "    # paraphrase = paraphraser.paraphrase(text) # let's not do this for speed reasons, and because there _may_ be something wrong with how we use the paraphraser\n",
    "\n",
    "    # chose random text with the same label\n",
    "    random_text = label_groups.get_group(label).sample(1)[\"text\"].values[0]\n",
    "\n",
    "    sample = {\n",
    "        \"semantic_sentence\": text,\n",
    "        \"paraphrase\": paraphrase,\n",
    "        \"style_sentence\": random_text,\n",
    "        \"label\": label,\n",
    "    }\n",
    "\n",
    "    transferred_sentence = style_transferer.transfer_style(text, random_text, truncate=True, max_length=25)\n",
    "    sample[\"transferred_sentence\"] = transferred_sentence\n",
    "\n",
    "    output_df.loc[i] = sample\n",
    "    if i % 10 == 0:\n",
    "        output_df.to_csv(\"data/decoded_cds/balanced/test_transferred.csv\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5854a06c42c722c9b376878a2b0ccc4f0377baad6105251f5d0bcbe5a7e06c30"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
