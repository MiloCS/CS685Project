{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"data\" # This may need to be changed on different machines\n",
    "\n",
    "# Make sure we're in the correct directory and make sure the data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.chdir(\"../..\") # Move up two directories because we're in src/nb and the data directory/path should be in/start at the root directory \n",
    "    assert os.path.exists(DATA_DIR), f\"ERROR: DATA_DIR={DATA_DIR} not found\"  # If we still can't see the data directory something is wrong\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "# get Dataset class\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from transformers import GPT2LMHeadModel, AdamW, GPT2Tokenizer\n",
    "\n",
    "from src.lib.decoder_dataset import DecoderDataset\n",
    "from src.lib.decoder import Decoder\n",
    "from src.lib.util import to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at models/gpt2_large were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.weight', 'transformer.extra_embedding_project.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab98ae53cbe45fb997e96712e1ccc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at models/gpt2_large were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.weight', 'transformer.extra_embedding_project.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b756085f83b43eaac4a1bd842ae286a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 11.77 GiB total capacity; 3.98 GiB already allocated; 35.56 MiB free; 4.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/bill/spring2022/685/CS685Project/src/nb/train_decoder.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/train_decoder.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(save_path):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/train_decoder.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATA_DIR, \u001b[39m\"\u001b[39m\u001b[39mdecoded_cds\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m), index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/train_decoder.ipynb#ch0000001vscode-remote?line=8'>9</a>\u001b[0m     dataset \u001b[39m=\u001b[39m DecoderDataset(df)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/train_decoder.ipynb#ch0000001vscode-remote?line=9'>10</a>\u001b[0m     dataset\u001b[39m.\u001b[39msave_state_dict(save_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/train_decoder.ipynb#ch0000001vscode-remote?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/src/lib/decoder_dataset.py:67\u001b[0m, in \u001b[0;36mDecoderDataset.__init__\u001b[0;34m(self, df, batch_size, state_dict)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder_dataset.py?line=64'>65</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf), batch_size)):\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder_dataset.py?line=65'>66</a>\u001b[0m     texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m][i:i\u001b[39m+\u001b[39mbatch_size])\n\u001b[0;32m---> <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder_dataset.py?line=66'>67</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstyle_encodings\u001b[39m.\u001b[39mappend(style_encoder\u001b[39m.\u001b[39;49mget_style_vector(texts)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder_dataset.py?line=67'>68</a>\u001b[0m \u001b[39m# concat style embeddings for all texts\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder_dataset.py?line=68'>69</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstyle_encodings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstyle_encodings, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m# style encodings of the paraphrases in the same order as in df\u001b[39;00m\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/src/lib/style_classifier.py:27\u001b[0m, in \u001b[0;36mStyleEncoder.get_style_vector\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_classifier.py?line=24'>25</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_classifier.py?line=25'>26</a>\u001b[0m     input_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39minput_ids\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_classifier.py?line=26'>27</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_ids)\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_classifier.py?line=27'>28</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mhidden_states\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/style_classifier.py?line=28'>29</a>\u001b[0m     \u001b[39m# style vector is the hidden state for the [CLS] token of the last layer\u001b[39;00m\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1545\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1536'>1537</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1537'>1538</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1538'>1539</a>\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1539'>1540</a>\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1540'>1541</a>\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1541'>1542</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1542'>1543</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1544'>1545</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1545'>1546</a>\u001b[0m     input_ids,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1546'>1547</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1547'>1548</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1548'>1549</a>\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1549'>1550</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1550'>1551</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1551'>1552</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1552'>1553</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1553'>1554</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1554'>1555</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1556'>1557</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1558'>1559</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=986'>987</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=988'>989</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=989'>990</a>\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=990'>991</a>\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=993'>994</a>\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=994'>995</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=995'>996</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=996'>997</a>\u001b[0m     embedding_output,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=997'>998</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=998'>999</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=999'>1000</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1000'>1001</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1001'>1002</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1002'>1003</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1003'>1004</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1004'>1005</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1005'>1006</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1006'>1007</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1007'>1008</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=1008'>1009</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=575'>576</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=576'>577</a>\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=577'>578</a>\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=581'>582</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=582'>583</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=583'>584</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=584'>585</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=585'>586</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=586'>587</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=587'>588</a>\u001b[0m         layer_head_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=588'>589</a>\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=589'>590</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=590'>591</a>\u001b[0m         past_key_value,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=591'>592</a>\u001b[0m         output_attentions,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=592'>593</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=594'>595</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=595'>596</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=459'>460</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=460'>461</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=461'>462</a>\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=468'>469</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=469'>470</a>\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=470'>471</a>\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=471'>472</a>\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=472'>473</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=473'>474</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=474'>475</a>\u001b[0m         head_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=475'>476</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=476'>477</a>\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=477'>478</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=478'>479</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=480'>481</a>\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=391'>392</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=392'>393</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=393'>394</a>\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=399'>400</a>\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=400'>401</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=401'>402</a>\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=402'>403</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=403'>404</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=404'>405</a>\u001b[0m         head_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=405'>406</a>\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=406'>407</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=407'>408</a>\u001b[0m         past_key_value,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=408'>409</a>\u001b[0m         output_attentions,\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=409'>410</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=410'>411</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=411'>412</a>\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:340\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=336'>337</a>\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=337'>338</a>\u001b[0m     attention_probs \u001b[39m=\u001b[39m attention_probs \u001b[39m*\u001b[39m head_mask\n\u001b[0;32m--> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=339'>340</a>\u001b[0m context_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(attention_probs, value_layer)\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=341'>342</a>\u001b[0m context_layer \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py?line=342'>343</a>\u001b[0m new_context_layer_shape \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_head_size,)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 11.77 GiB total capacity; 3.98 GiB already allocated; 35.56 MiB free; 4.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "datasets = {}\n",
    "for dataset_name in [\"dev\", \"test\", \"train\"]:\n",
    "    save_path = os.path.join(DATA_DIR, \"decoded_cds\", \"balanced\", f\"{dataset_name}_dataset.pth\")    \n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        df = pd.read_csv(os.path.join(DATA_DIR, \"decoded_cds\", \"balanced\", f\"{dataset_name}.csv\"), index_col=0)\n",
    "        dataset = DecoderDataset(df)\n",
    "        dataset.save_state_dict(save_path)\n",
    "    else:\n",
    "        dataset = DecoderDataset.from_state_dict(save_path)\n",
    "    \n",
    "    datasets[dataset_name] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at models/gpt2_large were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.bias', 'transformer.extra_embedding_project.weight']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "learning_rate = 5e-5\n",
    "optimizer_name = \"AdamW\"\n",
    "\n",
    "data_loaders = {}\n",
    "for dataset_name in datasets:\n",
    "    data_loaders[dataset_name] = DataLoader(datasets[dataset_name], batch_size=batch_size, num_workers=10)\n",
    "\n",
    "decoder = Decoder().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a51d6a352104c19b99b0d01857552ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "loss_history = []\n",
    "val_loss_history = []\n",
    "acc_history = []       \n",
    "\n",
    "iter_count = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    decoder.train()\n",
    "    pbar = tqdm(data_loaders[\"train\"])\n",
    "    for batch in pbar:\n",
    "        \n",
    "        batch = to_device(batch, device)\n",
    "\n",
    "        x, y = batch\n",
    "\n",
    "        label, label_idx = y\n",
    "\n",
    "        logits = decoder(x).logits[:, label_idx].diagonal().t()\n",
    "\n",
    "        batch_acc = (logits.argmax(dim=1) == label_idx).float().mean()\n",
    "        acc_history.append(batch_acc)\n",
    "\n",
    "        # calculate loss and backprop\n",
    "        loss = loss_fn(logits, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "        loss_history.append(loss_value)\n",
    "\n",
    "        mean_loss = np.mean(loss_history[-300:])\n",
    "        mean_acc = np.mean(acc_history[-300:])\n",
    "        pbar.set_description(f\"Epoch {epoch} Loss: {mean_loss:.4f} Acc: {mean_acc:.4f}\")\n",
    "\n",
    "        if iter_count % 1000 == 0:\n",
    "            pass\n",
    "    \n",
    "        iter_count += 1\n",
    "        \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        decoder.eval()\n",
    "        total_val_loss = 0\n",
    "        val_loss_count = 0\n",
    "        for batch in data_loaders[\"dev\"]:\n",
    "            batch = to_device(batch, device)\n",
    "\n",
    "            x, y = batch\n",
    "\n",
    "            label, label_idx = y\n",
    "\n",
    "            logits = decoder(x).logits[:, label_idx].diagonal().t()\n",
    "\n",
    "            loss = loss_fn(logits, label)\n",
    "\n",
    "            loss_value = loss.item()\n",
    "            total_val_loss += loss_value\n",
    "            val_loss_count += 1\n",
    "        \n",
    "        val_loss_history.append(total_val_loss / val_loss_count)\n",
    "    \n",
    "    # save model checkpoint\n",
    "    avg_loss = np.mean(loss_history[-len(data_loaders[\"train\"]):])\n",
    "    model_name = f\"decoder_{epoch}_{avg_loss:.4f}\"\n",
    "    save_path = os.path.join(\"decoder_checkpoints\", \"balanced\", model_name)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path) \n",
    "    torch.save(decoder.state_dict(), os.path.join(save_path, \"model.pth\"))\n",
    "    # save loss histories\n",
    "    histories = {\n",
    "        \"loss_history\": loss_history,\n",
    "        \"val_loss_history\": val_loss_history,\n",
    "        \"acc_history\": acc_history\n",
    "    }\n",
    "    with open(os.path.join(save_path, \"history.json\"), \"w\") as f:\n",
    "        json.dump(histories, f)\n",
    "    # save config\n",
    "    config = {\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"optimizer\": optimizer_name,\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_path, \"config.json\"), \"w\") as f:\n",
    "        json.dump(config, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5854a06c42c722c9b376878a2b0ccc4f0377baad6105251f5d0bcbe5a7e06c30"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
