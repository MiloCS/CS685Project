{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"data\" # This may need to be changed on different machines\n",
    "\n",
    "# Make sure we're in the correct directory and make sure the data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.chdir(\"../..\") # Move up two directories because we're in src/nb and the data directory/path should be in/start at the root directory \n",
    "    assert os.path.exists(DATA_DIR), f\"ERROR: DATA_DIR={DATA_DIR} not found\"  # If we still can't see the data directory something is wrong\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "# get Dataset class\n",
    "from src.lib.decoder import Decoder\n",
    "from src.lib.paraphrase_model import Paraphraser\n",
    "from src.lib.style_classifier import StyleEncoder\n",
    "from src.lib.style_transfer import StyleTransferer\n",
    "from src.lib.util import to_device\n",
    "from transformers import GPT2LMHeadModel, AdamW, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_decoder(state_dict_path):\n",
    "    state_dict = torch.load(state_dict_path)\n",
    "    for key in state_dict:\n",
    "        state_dict[key] = state_dict[key].cpu()\n",
    "    decoder = Decoder()\n",
    "    decoder.load_state_dict(state_dict)\n",
    "    return decoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at models/gpt2_large were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.weight', 'transformer.extra_embedding_project.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path = \"training_results/decoder_0_0.0979/model.pth\"\n",
    "decoder = load_decoder(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the built in generate method to see if our model has brain damage or if if there's a problem with our generate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = decoder.gpt2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"paraphrase this you insufferable diva <bos> you're a fool, you fool, you\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = \"paraphrase this you insufferable diva<bos>\"\n",
    "# tokenize\n",
    "tokenized = decoder.tokenizer(input_sentence, return_tensors=\"pt\")\n",
    "input_ids = tokenized[\"input_ids\"].to(device)\n",
    "attn_mask = tokenized[\"attention_mask\"].to(device)\n",
    "generated_ids = gpt2.generate(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "# decode the generated ids\n",
    "generated_sentence = decoder.tokenizer.decode(generated_ids[0])\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at models/gpt2_large were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.weight', 'transformer.extra_embedding_project.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "paraphrase = Paraphraser()\n",
    "decoder.gpt2 = paraphrase.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_encoder = StyleEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style_encoding = style_encoder.get_style_vector([style_sentence]).squeeze(0)\n",
    "# style_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional_embeds = decoder.gpt2.transformer.wpe.weight\n",
    "# token_embeds = decoder.gpt2.transformer.wte.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_input(semantic_sentence, style_sentence, style_encoder, decoder):\n",
    "#     positional_embeds = decoder.gpt2.transformer.wpe.weight\n",
    "#     token_embeds = decoder.gpt2.transformer.wte.weight\n",
    "\n",
    "#     style_encoding = style_encoder.get_style_vector([style_sentence]).squeeze(0) # (768)\n",
    "\n",
    "#     max_length = 50\n",
    "#     tokenized = decoder.tokenizer([semantic_sentence], return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "#     para_ids = tokenized[\"input_ids\"] # (1, para_length)\n",
    "#     para_attn = tokenized[\"attention_mask\"].squeeze(0) # (para_length)\n",
    "\n",
    "#     para_embeds = token_embeds[para_ids].squeeze(0).detach() # (para_length, 1280)\n",
    "#     para_pos = positional_embeds[np.arange(0, len(para_embeds))].detach() # (para_length, 1280)\n",
    "\n",
    "#     target_embeds = token_embeds[[decoder.tokenizer.bos_token_id, decoder.tokenizer.pad_token_id]].detach() # (2, 1280)\n",
    "#     target_pos = positional_embeds[[len(para_ids), len(para_ids)+1]].detach() # (2, 1280)\n",
    "\n",
    "#     target_attn = torch.tensor([1, 0])\n",
    "\n",
    "#     attn_mask = torch.ones(2 + len(para_attn) + len(target_attn)) # (2 + para_length + target_length)\n",
    "#     attn_mask[1:len(para_attn)+1] = para_attn\n",
    "#     attn_mask[len(para_attn)+2:] = target_attn # just one for the BOS token\n",
    "#     attn_mask = attn_mask\n",
    "\n",
    "#     bos_pos = positional_embeds[len(para_ids) + 1].detach()\n",
    "\n",
    "#     style_encoding = style_encoding.unsqueeze(0)\n",
    "#     para_embeds = para_embeds.unsqueeze(0)\n",
    "#     para_pos = para_pos.unsqueeze(0)\n",
    "#     bos_pos = bos_pos.unsqueeze(0)\n",
    "#     target_embeds = target_embeds.unsqueeze(0)\n",
    "#     target_pos = target_pos.unsqueeze(0)\n",
    "#     attn_mask = attn_mask.unsqueeze(0)\n",
    "\n",
    "#     x = (\n",
    "#         style_encoding,\n",
    "#         (para_embeds, para_pos),\n",
    "#         bos_pos,\n",
    "#         (target_embeds, target_pos),\n",
    "#         attn_mask.unsqueeze(0)\n",
    "#     )\n",
    "\n",
    "#     return x\n",
    "\n",
    "\n",
    "# def generate(x, decoder, truncate=False, max_length=50, device=None):\n",
    "#     if device is None:\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#     x = to_device(x, device)\n",
    "#     decoder = decoder.to(device)\n",
    "    \n",
    "#     # print sum of attn_mask\n",
    "    \n",
    "\n",
    "#     generated_ids = []\n",
    "#     generated_logits = []\n",
    "#     with torch.no_grad():\n",
    "#         i = 0\n",
    "#         while i < max_length or not truncate:\n",
    "#             i += 1\n",
    "\n",
    "#             style_encoding, para, bos_pos, target, attn_mask = x\n",
    "#             target_embeds, target_pos = target\n",
    "\n",
    "#             print(attn_mask.sum())\n",
    "\n",
    "#             output = decoder(x)\n",
    "\n",
    "#             logits = output.logits[0, -1, :]\n",
    "#             token_id = logits.argmax()\n",
    "\n",
    "#             generated_logits.append(logits)\n",
    "\n",
    "\n",
    "#             # check if token_id is eos\n",
    "#             if token_id == decoder.tokenizer.eos_token_id:\n",
    "#                 break\n",
    "\n",
    "#             # add generated id \n",
    "#             generated_ids.append(token_id.item())\n",
    "#             next_embedding = decoder.gpt2.transformer.wte.weight[token_id]\n",
    "#             next_pos_embed = decoder.gpt2.transformer.wpe.weight[target_pos.shape[1] + 1]\n",
    "\n",
    "#             # update the target embedding\n",
    "#             target_embeds = torch.cat([target_embeds, next_embedding.unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "#             # update the target position\n",
    "#             target_pos = torch.cat([target_pos, next_pos_embed.unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "#             # update the attention mask\n",
    "#             attn_mask = torch.cat([attn_mask, torch.ones(1, 1, 1).to(device)], dim=2)\n",
    "\n",
    "#             # repackage x\n",
    "#             x = (\n",
    "#                 style_encoding,\n",
    "#                 para,\n",
    "#                 bos_pos,\n",
    "#                 (target_embeds, target_pos),\n",
    "#                 attn_mask\n",
    "#             )\n",
    "        \n",
    "#     return generated_ids, generated_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_sentence = \"Hello, how are you?\"\n",
    "style_sentence = \"The all-seeing sun Ne'er saw her match since first the world begun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you're a little, you're a little bit, you're a little bit, you're a little bit, you're a little bit, you're a little bit, you're a little bit, you're a little bit, you're a\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = StyleTransferer(style_encoder, decoder, device)\n",
    "st.transfer_style(semantic_sentence, style_sentence, truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9., device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m input_sequence \u001b[39m=\u001b[39m build_input(semantic_sentence, style_sentence, style_encoder, decoder)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m tokens, logits \u001b[39m=\u001b[39m generate(input_sequence, decoder, device\u001b[39m=\u001b[39;49mdevice, truncate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb Cell 11'\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(x, decoder, truncate, max_length, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb#ch0000007vscode-remote?line=63'>64</a>\u001b[0m target_embeds, target_pos \u001b[39m=\u001b[39m target\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb#ch0000007vscode-remote?line=65'>66</a>\u001b[0m \u001b[39mprint\u001b[39m(attn_mask\u001b[39m.\u001b[39msum())\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb#ch0000007vscode-remote?line=67'>68</a>\u001b[0m output \u001b[39m=\u001b[39m decoder(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb#ch0000007vscode-remote?line=69'>70</a>\u001b[0m logits \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mlogits[\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bobiwan/home/bill/spring2022/685/CS685Project/src/nb/style_transfer_test.ipynb#ch0000007vscode-remote?line=70'>71</a>\u001b[0m token_id \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39margmax()\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/bill/spring2022/685/CS685Project/env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/spring2022/685/CS685Project/src/lib/decoder.py:40\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder.py?line=36'>37</a>\u001b[0m para_ids, para_pos \u001b[39m=\u001b[39m para\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder.py?line=37'>38</a>\u001b[0m target_ids, target_pos \u001b[39m=\u001b[39m target\n\u001b[0;32m---> <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder.py?line=39'>40</a>\u001b[0m para_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgpt2\u001b[39m.\u001b[39;49mtransformer\u001b[39m.\u001b[39;49mwte\u001b[39m.\u001b[39;49mweight[para_ids]\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder.py?line=40'>41</a>\u001b[0m target_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgpt2\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mwte\u001b[39m.\u001b[39mweight[target_ids]\n\u001b[1;32m     <a href='file:///home/bill/spring2022/685/CS685Project/src/lib/decoder.py?line=41'>42</a>\u001b[0m bos_embed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgpt2\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mwte\u001b[39m.\u001b[39mweight[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mbos_token_id]\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "input_sequence = build_input(semantic_sentence, style_sentence, style_encoder, decoder)\n",
    "tokens, logits = generate(input_sequence, decoder, device=device, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(15365, device='cuda:0')]\n",
      "[tensor(15365, device='cuda:0')]\n",
      "[tensor(15365, device='cuda:0')]\n",
      "[tensor(15365, device='cuda:0')]\n",
      "[tensor(15365, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print([logits[0].argmax()])\n",
    "print([logits[1].argmax()])\n",
    "print([logits[2].argmax()])\n",
    "print([logits[3].argmax()])\n",
    "print([logits[4].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTSENTS'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode the tokens\n",
    "text = decoder.tokenizer.decode(tokens)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "tokenized = decoder.tokenizer([semantic_sentence], return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "para_ids = tokenized[\"input_ids\"]\n",
    "para_attn = tokenized[\"attention_mask\"].squeeze(0)\n",
    "print(para_ids.shape)\n",
    "print(para_attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_embeds = token_embeds[para_ids].squeeze(0).detach()\n",
    "para_pos = positional_embeds[np.arange(0, len(para_embeds))].detach()\n",
    "# para_embeds += para_pos\n",
    "print(para_embeds.shape)\n",
    "print(para_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embeds = token_embeds[decoder.tokenizer.bos_token_id].unsqueeze(0).detach()\n",
    "target_pos = positional_embeds[len(para_ids)].unsqueeze(0).detach()\n",
    "# target_embeds += target_pos\n",
    "print(target_pos.shape)\n",
    "print(target_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_attn = torch.tensor([1])\n",
    "\n",
    "attn_mask = torch.ones(2 + len(para_attn) + len(target_attn))\n",
    "attn_mask[1:len(para_attn)+1] = para_attn\n",
    "attn_mask[len(para_attn)+2:] = target_attn # just one for the BOS token\n",
    "attn_mask = attn_mask\n",
    "print(attn_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_pos = positional_embeds[len(para_ids) + 1].detach()\n",
    "print(bos_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"style_encoding\", style_encoding.shape)\n",
    "print(\"para_embeds\", para_embeds.shape)\n",
    "print(\"para_pos\", para_pos.shape)\n",
    "print(\"bos_pos\", bos_pos.shape)\n",
    "print(\"target_embeds\", target_embeds.shape)\n",
    "print(\"target_pos\", target_pos.shape)\n",
    "print(\"attn_mask\", attn_mask.shape)\n",
    "\n",
    "# unsqueeze to add batch dimension\n",
    "style_encoding = style_encoding.unsqueeze(0)\n",
    "para_embeds = para_embeds.unsqueeze(0)\n",
    "para_pos = para_pos.unsqueeze(0)\n",
    "bos_pos = bos_pos.unsqueeze(0)\n",
    "target_embeds = target_embeds.unsqueeze(0)\n",
    "target_pos = target_pos.unsqueeze(0)\n",
    "attn_mask = attn_mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (\n",
    "    style_encoding,\n",
    "    (para_embeds, para_pos),\n",
    "    bos_pos,\n",
    "    (target_embeds, target_pos),\n",
    "    attn_mask.unsqueeze(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = to_device(x, \"cuda\")\n",
    "decoder = decoder.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_id = output.logits.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5854a06c42c722c9b376878a2b0ccc4f0377baad6105251f5d0bcbe5a7e06c30"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
